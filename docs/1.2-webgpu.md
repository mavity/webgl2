# WebGPU Implementation Plan

## üéØ Objective

Implement a WebGPU API surface (`navigator.gpu`) that runs entirely in WebAssembly/Rust, mirroring the architecture of the existing WebGL2 implementation. This allows for deterministic execution, advanced debugging (DWARF), and software rasterization of WebGPU workloads.

## üèóÔ∏è Architecture

The implementation follows the same "Split-Brain" architecture as the WebGL2 implementation:

1.  **Frontend (JavaScript)**: A thin API layer (`src/webgpu_context.js`) that implements the standard WebGPU interfaces (`GPU`, `GPUAdapter`, `GPUDevice`, etc.) and forwards calls to the WASM module.
2.  **Backend (Rust/WASM)**: A dedicated module (`src/webgpu/`) that hosts the `wgpu-core` state machine and the software rasterizer integration.
3.  **Core (Shared)**: Reuses the existing `naga` compiler toolchain and software rasterizer.

### Key Strategic Decisions

1.  **Leverage `wgpu-core`**: Unlike the WebGL2 implementation where we built a custom state machine, for WebGPU we will use the [wgpu-core](https://github.com/gfx-rs/wgpu/tree/trunk/wgpu-core) crate. It provides a complete, spec-compliant implementation of WebGPU state tracking, validation, and logic.
2.  **Reuse `naga_wasm_backend`**: Since WebGL2 (GLSL) and WebGPU (WGSL) both compile to the same `naga::Module` IR, we will reuse the existing compiler backend. We only need to generalize the memory layout to support generic Bind Groups instead of fixed WebGL uniforms/attributes.
3.  **Synchronous Execution Model**: While WebGPU is asynchronous, our WASM implementation is single-threaded. `queue.submit` will execute synchronously. We must manually advance the `wgpu-core` state machine (poll/maintain) immediately after submission to satisfy validation rules.

## üõ†Ô∏è Implementation Steps

### Phase 1: Foundation & API Surface

**Step 1: Dependencies**
- Add `wgpu-core`, `wgpu-types`, and `wgpu-hal` to `Cargo.toml` using **local paths** (e.g., `path = "wgpu-fork/wgpu-core"`) to ensure version compatibility with the local `naga` fork.
- Update `naga` dependency to include the `wgsl-in` feature.
- Configure features to ensure compatibility with `wasm32-unknown-unknown` (disable native platform features).

**Step 2: Refactor Core Rasterizer (Shared Engine)**
- **Extract**: Move the rasterization logic (vertex fetching, barycentric interpolation, fragment shading loop) from `src/webgl2_context/drawing.rs` into `src/wasm_gl_emu/rasterizer.rs`.
- **Define Pipeline**: Create a `RasterPipeline` struct that holds the shader function table index and memory layout, decoupling it from WebGL's `Program` object.
- **Generalize**: Replace hardcoded WebGL memory offsets (e.g., `0x2000` for attributes) with a flexible `RenderState` struct that accepts generic pointers or slices.
- **Verify**: Update the existing WebGL2 implementation to use this new shared API, ensuring no regressions in `cargo test`.
- **Goal**: Create a clean, "driver-agnostic" software rasterizer API that `wgpu-hal` can target.

**Step 3: Rust Backend Structure (`src/webgpu/`)**
- Create `src/webgpu/mod.rs`: Public API and `extern "C"` exports.
- Create `src/webgpu/adapter.rs`: Instance, Adapter, and Device initialization.
- Initialize `wgpu_core::global::Global` to hold the WebGPU state.
- Map `wgpu_core::id::Id` types to integer handles exposed to JS.

**Step 4: JavaScript Frontend (`src/webgpu_context.js`)**
- Implement the `navigator.gpu` entry point.
- Create classes for `GPUAdapter`, `GPUDevice`, `GPUQueue`, `GPUBuffer`, etc.
- **Async/Await**: Implement `requestAdapter` and `requestDevice` as Promises that resolve immediately (since the backend is synchronous).

### Phase 2: Execution & Rasterization

**Step 5: The "Empty" Backend**
- Initially configure `wgpu-core` to use the `Empty` backend.
- This allows full implementation and testing of the API surface, object creation, and validation logic without needing a working rasterizer.

**Step 6: Software Rasterizer Integration (The "Plugin")**
Implement the `wgpu-hal` traits in `src/webgpu/backend.rs` to bridge `wgpu-core` to our `wasm_gl_emu`:
- **`Api`**: Entry point for the "WASM Soft-GPU" driver.
- **`Device`**: Map resource creation (Buffers, Textures) to emulator memory allocations.
- **Texture Support**: Implement software decoding for compressed formats (BC, ETC2) using a pure-Rust decoder. Implement `Sampler` logic (filtering, wrapping) in software.
- **`CommandEncoder`**: Translate WebGPU commands (`draw`, `set_bind_group`) into calls to `wasm_gl_emu` rasterization functions. **Implement MSAA resolve logic for multi-sample render targets.**
- **`Queue`**: Execute the recorded command lists on the emulator.

### Phase 2.5: Presentation & Interop

**Step 7: Presentation Layer (`GPUCanvasContext`)**
- **JS**: Implement `GPUCanvasContext.configure()` to allocate a shared backing store (e.g., a specific memory offset or `ImageData`).
- **Rust**: Implement `wgpu_hal::Surface` as a "Soft Surface" that writes to this shared memory.
- **Present**: Implement `surface.present()` to trigger a blit from the WASM memory to the HTML Canvas (via `putImageData` or `createImageBitmap`).

**Step 8: Data Interop (`mapAsync`)**
- **Model**: Follow the standard "Segregated Memory" model to ensure safety and avoid "View Invalidation" bugs.
- **Read**: `getMappedRange` creates a *copy* of the data in a JavaScript `ArrayBuffer`.
- **Write**: `getMappedRange` returns a temporary JavaScript `ArrayBuffer`. On `unmap()`, this data is copied back into the WASM memory.
- **Benefit**: This isolates JavaScript views from WASM memory growth, preventing "detached buffer" errors and ensuring spec compliance.

### Phase 3: Compiler Generalization

**Step 9: Generalize `naga_wasm_backend`**
- Refactor `MemoryLayout` to support generic Bind Group layouts.
- Update the compiler to map `(BindGroup, Binding)` to memory offsets in the generated WASM.

**Step 10: WGSL Support**
- Integrate `naga::front::wgsl` to parse WGSL source code into `naga::Module`.
- This is straightforward as `naga` is native to WGSL, unlike GLSL which required complex introspection.

**Step 11: Basic Compute Support**
- Implement `dispatch` command in the emulator.
- Support compute shaders that do *not* use `workgroupBarrier()`.
- **Atomics**: Fully supported. Since the emulator executes threads sequentially, atomic operations (like `atomicAdd`) are naturally safe and do not require complex locking or synchronization logic.
- This covers the majority of "embarrassingly parallel" use cases (physics, particles, ray tracing) without requiring complex coroutine compilation.
- **Advanced Compute (Barriers)**: Support `workgroupBarrier()` by implementing a coroutine-based execution model in the compiler backend to handle thread yielding and synchronization.
