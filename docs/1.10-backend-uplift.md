# WASM backend is experimental, and this is the plan to shake it up to a full blown compiler

First we will review the current state of WASM backend now broken down into its functional parts, describing exactly how data flows and how decisions are made.

### 1. The Compiler Shell & Orchestration
**Location:** backend.rs
- **State Management:** The `Compiler` struct holds the `naga::Module`, a `wasm_encoder::Module`, and maps for `Type`, `Function`, and `Global` handles to WASM indices.
- **Traversal:** It performs a linear pass over `module.global_variables`, then `module.functions`, and finally `module.entry_points`.
- **Function Mapping:** Each Naga function is mapped to a WASM function. The `FunctionContext` tracks locals, the current `wasm_encoder::Function`, and the `naga::Function` being processed.
- **Entry Points:** Entry points are wrapped in a WASM function that initializes "pointers" (globals) to memory offsets before calling the internal implementation.

### 2. Expression Translation (Scalarization)
**Location:** expressions.rs
- **Mechanism:** Uses `translate_expression` to match on `naga::Expression`. Since WASM is scalar-only (in this implementation), multi-component types (vectors/matrices) are handled by `translate_expression_component`.
- **Stack Operations:** Each call emits one or more `wasm_encoder::Instruction`s onto the operand stack. 
- **Type Checking:** Uses `module.types[handle].inner` to determine if it should emit `I32`, `F32`, etc.
- **Component Access:** `Access` and `AccessIndex` expressions calculate memory offsets or pick specific "lanes" of a vector by adding a component-index multiplier to a base pointer.

### 3. Statement & Control Flow handling
**Location:** control_flow.rs
- **Block Mapping:** Naga `Statement` blocks are mapped to WASM `Block`, `Loop`, and `If` types.
- **The "Return-to-Memory" Pattern:** Instead of WASM function returns, entry points often write their final results (like `gl_Position` or color outputs) into specific memory addresses. `store_components_to_memory` iterates through lanes and performs `f32.store` or `i32.store`.
- **Variable Mapping:** `naga::LocalVariable` handles are mapped directly to WASM locals. `naga::GlobalVariable` handles are mapped to offsets relative to specific "Base Pointers" stored in WASM globals.

### 4. Memory Partitioning & Layout
**Location:** output_layout.rs
- **Address Spaces:** The implementation defines a set of "Base Pointer" globals: `ATTR_PTR_GLOBAL`, `UNIFORM_PTR_GLOBAL`, `VARYING_PTR_GLOBAL`, etc.
- **Slot Allocation:** Layout is computed via logical "locations." For example, attributes are spaced at 64-byte intervals (`location * 64`), and varyings at 16-byte intervals (`location * 16`). Note: the backend special-cases `gl_Position` by placing it at offset 0 and advancing the `varying_offset` by 16 bytes (see `src/naga_wasm_backend/backend.rs`).
- **Texture/Sampler Mapping:** These are treated as indices into a host-provided table, mapped via `compute_texture_offset`.

### 5. Type & Signature Translation
**Location:** types.rs
- **Scalar Mapping:** `TypeInner::Scalar` and `TypeInner::Vector` components are mapped to `ValType::F32`, `I32`, or `I64`.
- **Component Counting:** `component_count` and `vector_component_count` helpers are used to determine how many times to repeat a load/store operation or how many WASM parameters a function requires.
- **Simplification:** Currently, most scalar types are treated as 4-byte values in memory calculations, regardless of the Naga `bit_width`. This is visible in places like `type_size(...).unwrap_or(4)` and explicit `component * 4` arithmetic in `src/naga_wasm_backend/expressions.rs`, which should be replaced by scalar-width-aware helpers.

### 6. Resource Identification & Linking
**Location:** shaders.rs (Frontend side)
- **Metadata Extraction:** Before the backend runs, this code scans the Naga module to identify which globals are attributes, uniforms, or varyings.
- **Heuristic Matching:** It identifies "Special" variables (like the vertex position or fragment color) by matching string names (e.g., `gl_Position`, `color`, `fragColor`) and assigns them to specific layout slots. Note: similar name-based checks also appear in backend files (`src/naga_wasm_backend/backend.rs`, `src/naga_wasm_backend/expressions.rs`), so heuristics exist in both front- and back-end.
- **Binding resolution:** It maps Naga `Binding` objects to the internal layout slots used by the WASM backend.

---

## Data Flow
1. **Source IR:** `naga::Module` (from WGSL/GLSL).
2. **Analysis:** Identify IO roles via Name + Binding heuristics.
3. **Setup:** Emit WASM Globals for memory base-pointers.
4. **Translation:** Lower structured expressions to a flat sequence of stack instructions.
5. **Output:** A `.wasm` binary where functions read/write to partitioned linear memory based on hardcoded slot math.
6. **Validation:** There is no centralized `InterfaceDescriptor` or dedicated entry-point validation pass; matching and validation are performed piecemeal across frontend and backend.


### Stage 1: The Metadata Deconstruction (The "Contract")
**Files:** shaders.rs
- **Symbol:** Logic within `create_program` (or the internal closure `get_type_info`).
- **Data Structures:** `attribute_types`, `uniform_types`, and `varying_types` (stored in the `Webgl2Program` or `ProgramContext`).
**Data Source:** `naga::Module` + `naga::valid::ModuleInfo`
**Transformation:** Before the backend even sees the module, shaders.rs performs a "census" of the IR.
- **The Flow:** It iterates over `global_variables`, filtering by `AddressSpace`.
- **The Output:** It produces three primary lists: `attribute_types`, `uniform_types`, and `varying_types`. 
- **The Grainy Truth:** These lists are the "hidden" contract. They store basic type codes (Float/Int/Uint) and component counts. Crucially, the **location index** is derived from their order in these lists, creating a positional dependency that must be perfectly synced with the backend's slot math. The frontend uses `Binding` information where present and also falls back to name-based heuristics (e.g., `gl_Position`, `fragColor`, names ending with `Color`) when explicit bindings are absent.

### Stage 2: The Environment Setup (Base Pointer "Plumbing")
**Files:** backend.rs, output_layout.rs
- **Symbol:** `Compiler::new` and the constants `ATTR_PTR_GLOBAL`, `UNIFORM_PTR_GLOBAL`, `VARYING_PTR_GLOBAL`.
**Data Source:** `Compiler::new`
**Transformation:** The backend creates the "registers" of our virtual machine.
- **The Flow:** `Compiler::new` initializes the `wasm_encoder::Module` and immediately emits `Global` entries. It uses the index constants defined in `output_layout.rs` to ensure that when an expression later asks for a "Uniform", the code refers to the correct WASM global index.  It emits a set of WASM Globals (`i32`). Each global is a base pointer for a specific memory region (e.g., `UNIFORM_PTR`, `ATTR_PTR`).
- **The Grainy Truth:** These globals are "floating" handles. Their values are patched or provided by the host environment at runtime. The backend generates code that assumes these globals *will* exist at specific indices (0, 1, 2...). Runtime/emulator code (for example, `src/wasm_gl_emu/rasterizer.rs`) reads and writes these memory regions, so the host or emulator must initialize base pointers accordingly.


### Stage 3: Type Expansion (The "Signature Flattening")
**Files:** types.rs
- **Symbol:** `naga_to_wasm_types`, `scalar_to_wasm`, and `component_count`.
**Data Source:** `naga::types::TypeInner` -> `wasm_encoder::ValType`
**Transformation:** Naga's tree-like types are "crushed" into WASM's flat parameter lists.
- **The Flow:** When a function call is encountered, the backend looks up the Naga function signature. In `Compiler::compile_function`, the Naga signature is passed to `naga_to_wasm_types`. This function recursively visits `TypeInner::Vector` and `TypeInner::Matrix`, calling `scalar_to_wasm` for each lane and flattening them into a linear `Vec<ValType>`.
- **The Logic:** If a function takes a `vec3<f32>`, the `naga_to_wasm_types` helper expands this into three `F32` parameters in the WASM function signature.
- **The Grainy Truth:** The backend performs a "structural unrolling." It forgets the `vec3` structure at the boundary and communicates strictly in scalar sequences. If the caller and callee disagree on the unrolling logic, the stack corrupts silently.


### Stage 4: Expression Lowering (The "Scalarization Loop")
**Files:** expressions.rs
- **Symbol:** `translate_expression_component` and `translate_binary_op`.
**Data Source:** `naga::Expression` -> `Vec<Instruction>`
**Transformation:** This is where the kinetic flow is most aggressive. A single IR handle is expanded into a sequence of stack-shuffling ops.
- **The Flow:** `translate_expression_component` is called recursively. Every complex Naga expression handle is processed via `translate_expression_component(component_idx)`. 
- **The Logic:** If the IR shows a `BinaryOperator`, the code enters `translate_binary_op`. Instead of emitting one opcode, it loops over the `component_count`, emitting a "component-fetch -> scalar-op" sequence for every lane (0 to N).
- **The Workhorse:** For a `BinaryOperator` (e.g., `vec3 + vec3`), the engine:
    1. Computes the offset for component $i$.
    2. Emits code to fetch component $i$ from operand A.
    3. Emits code to fetch component $i$ from operand B.
    4. Emits the scalar opcode (e.g., `F32Add`).
    5. Repeats for $i = 0, 1, 2$.
- **The Grainy Truth:** The backend does **not** generate a single "add" instruction. It generates a "burst" of instructions. The "intelligence" of the vector is lost; it becomes a loop in the compiler's logic rather than a structure in the generated code.


### Stage 5: The "Side-Channel" Return (Memory Siphoning)
**Files:** control_flow.rs
- **Symbol:** `translate_statement` (Return arm), `store_components_to_memory`, and `store_single_value_to_output`.
**Data Source:** `naga::Statement::Return` -> `wasm_encoder::Instruction::Store`
**Transformation:** Entry points break the standard function return flow.
- **The Flow:** When an entry point returns, `store_components_to_memory` triggers. When `translate_statement` encounters `naga::Statement::Return`, it doesn't just emit a WASM `return`. It calls `store_components_to_memory`, which calculates the memory destination using `output_layout::compute_output_destination` and generates a burst of `Instruction::F32Store` or `I32Store` calls.
- **The Logic:** It looks up the "Output Destination" (determined by the name-based or binding-based heuristics). It then emits a series of `f32.store` instructions relative to `VARYING_PTR_GLOBAL`.
- **The Grainy Truth:** The WASM function technically returns `void` (or nothing). The "real" data flows out through linear memory. This "siphoning" happens at every `Return` statement, potentially multiple times in a complex shader, manually writing to the varying slots.

### Stage 6: The Texture/Sampler "Index Mapping"
**Files:** output_layout.rs, expressions.rs
- **Symbol:** `compute_texture_offset` and `ImageSample` handling in `translate_expression`.
**Data Source:** `naga::GlobalVariable` (Storage: Image/Sampler)
**Transformation:** Handles are converted to immediate indices.
- **The Flow:** When a texture sample operation is called, the backend doesn't pass a "texture object." When `translate_expression` hits an `ImageSample` or `ImageLoad`, it calls `compute_texture_offset` to resolve the Naga handle to a raw integer index. This index is pushed onto the WASM stack as a constant (`I32Const`) immediately before calling the host-imported sampling function.
- **The Logic:** It resolves the `GlobalVariable` handle to its binding index (e.g., `binding = 0`). 
- **The Grainy Truth:** The generated WASM emits a constant `i32` for that index. This index is then passed to a host-defined import function (like `sample_texture`). The backend is essentially generating a "call-by-index" protocol.


---

### Summary of Data Structures
- **`Compiler`** (backend.rs): The central state holding maps like `type_map`, `func_map`, and `global_map`.
- **`FunctionContext`** (backend.rs): Temporary storage for locals and labels during a single function's traversal.
- **`InterfaceDescriptor`** (Proposed in previous steps): This would be the new data structure to "harden" the flow between Stage 1 and Stage 2.

The data flow is a process of **continuous simplification**. 
1. **Source:** High-level structured IR.
2. **Intermediate:** A collection of scalar offsets and base-pointer globals.
3. **Final:** A linear stream of instructions where "structures" (vectors, matrices, varyings) exist only as specific offsets from a handful of global "anchor" pointers.
